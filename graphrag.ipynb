{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-14T16:06:57.140163Z",
     "start_time": "2026-01-14T16:06:52.963420Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import json\n",
    "\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain_experimental.graph_transformers import LLMGraphTransformer\n",
    "from langchain_community.graphs import Neo4jGraph\n",
    "from langchain_core.documents import Document\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain_groq import ChatGroq\n",
    "\n",
    "\n",
    "\n",
    "def clean_id(n):\n",
    "    return n.strip().lower()\n",
    "\n",
    "\n"
   ],
   "id": "29125228e5f7eb91",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/srichandrasamanapalli/Who to sue next/.venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2026-01-14T16:06:58.403241Z",
     "start_time": "2026-01-14T16:06:57.144211Z"
    }
   },
   "source": [
    "try:\n",
    "    graph = Neo4jGraph()\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "    exit()\n",
    "graph.query(\"\"\"CREATE VECTOR INDEX section_embedding IF NOT EXISTS FOR (s:Section) ON (s.embedding) OPTIONS {indexConfig: {`vector.dimensions`: 1024,`vector.similarity_function`: 'cosine'}}\"\"\")\n",
    "graph.query(\"\"\"CREATE VECTOR INDEX concept_embedding IF NOT EXISTS FOR (lc:LegalConcept) ON (lc.embedding) OPTIONS {indexConfig: {`vector.dimensions`: 1024,`vector.similarity_function`: 'cosine'}}\"\"\")"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/qs/9l_k0_vx1vzfw3cj8wkmym600000gn/T/ipykernel_83639/3286139412.py:2: LangChainDeprecationWarning: The class `Neo4jGraph` was deprecated in LangChain 0.3.8 and will be removed in 1.0. An updated version of the class exists in the `langchain-neo4j package and should be used instead. To use it run `pip install -U `langchain-neo4j` and import as `from `langchain_neo4j import Neo4jGraph``.\n",
      "  graph = Neo4jGraph()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not connect to Neo4j database. Please ensure that the url is correct\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'graph' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mNameError\u001B[39m                                 Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[2]\u001B[39m\u001B[32m, line 6\u001B[39m\n\u001B[32m      4\u001B[39m     \u001B[38;5;28mprint\u001B[39m(e)\n\u001B[32m      5\u001B[39m     exit()\n\u001B[32m----> \u001B[39m\u001B[32m6\u001B[39m \u001B[43mgraph\u001B[49m.query(\u001B[33m\"\"\"\u001B[39m\u001B[33mCREATE VECTOR INDEX section_embedding IF NOT EXISTS FOR (s:Section) ON (s.embedding) OPTIONS \u001B[39m\u001B[33m{\u001B[39m\u001B[33mindexConfig: \u001B[39m\u001B[33m{\u001B[39m\u001B[33m`vector.dimensions`: 1024,`vector.similarity_function`: \u001B[39m\u001B[33m'\u001B[39m\u001B[33mcosine\u001B[39m\u001B[33m'\u001B[39m\u001B[33m}}\u001B[39m\u001B[33m\"\"\"\u001B[39m)\n\u001B[32m      7\u001B[39m graph.query(\u001B[33m\"\"\"\u001B[39m\u001B[33mCREATE VECTOR INDEX concept_embedding IF NOT EXISTS FOR (lc:LegalConcept) ON (lc.embedding) OPTIONS \u001B[39m\u001B[33m{\u001B[39m\u001B[33mindexConfig: \u001B[39m\u001B[33m{\u001B[39m\u001B[33m`vector.dimensions`: 1024,`vector.similarity_function`: \u001B[39m\u001B[33m'\u001B[39m\u001B[33mcosine\u001B[39m\u001B[33m'\u001B[39m\u001B[33m}}\u001B[39m\u001B[33m\"\"\"\u001B[39m)\n",
      "\u001B[31mNameError\u001B[39m: name 'graph' is not defined"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "graph.query(\"CREATE CONSTRAINT unique_chapter_id IF NOT EXISTS FOR (c:Chapter) REQUIRE c.id IS UNIQUE\")\n",
    "graph.query(\"CREATE CONSTRAINT unique_section_id IF NOT EXISTS FOR (s:Section) REQUIRE s.id IS UNIQUE\")\n",
    "allowed_nodes = [\"Provision\",\"Actor\",\"Category\",\"Violation\",\"Condition\",\"Remedy\",\"Penalty\",\"Authority\"]"
   ],
   "id": "21c2511bc2df77af",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "for node_label in allowed_nodes:\n",
    "    graph.query(\n",
    "        f\"CREATE CONSTRAINT unique_{node_label.lower()}_id IF NOT EXISTS FOR (n:{node_label}) REQUIRE n.id IS UNIQUE\")\n",
    "\n",
    "llm = ChatGoogleGenerativeAI(model='gemini-2.5-flash', temperature=0)\n",
    "embeddings = HuggingFaceEmbeddings(model_name=\"BAAI/bge-m3\")\n",
    "\n",
    "allowed_rels = [\"DEFINES\",\"QUALIFIES_AS\",\"INCLUDES\",\"EXCLUDES\",\"CONSTITUTES\",\"PROHIBITS\",\"ESTABLISHES\",\"FILED_BEFORE\",\"APPEALS_TO\",\"ALLOWS_RELIEF\",\"CARRIES_PENALTY\",\"LIABLE_FOR\",\"GRANTS_RIGHT\"]\n",
    "llm_transformer = LLMGraphTransformer(llm=llm, allowed_nodes=allowed_nodes, allowed_relationships=allowed_rels)\n",
    "\n"
   ],
   "id": "f0f2327bada1667b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "with open(\"cpa_anchored_refined_v2.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    data = json.load(f)\n",
    "    for chapter in data:\n",
    "        chapter_name = clean_id(chapter[\"chapter_name\"])\n",
    "        graph.query(\"MERGE (c:Chapter {id : $id})\", params={'id': chapter_name})\n",
    "        for section in chapter[\"sections\"]:\n",
    "\n",
    "            section_id = clean_id(str(section[\"section_id\"]))\n",
    "            section_title = clean_id(section[\"title\"])\n",
    "            text = section[\"title\"] + section[\"original_content\"]\n",
    "            section_embedding = embeddings.embed_query(text)\n",
    "            graph.query(\n",
    "                '''MATCH (c:Chapter {id : $cid}) MERGE (s:Section {id: $sid}) SET s.title=$title, s.text=$text, s.embedding=$embedding MERGE (c)-[:CONTAINS]->(s)''',\n",
    "                params={'cid': chapter_name, 'sid': section_id, 'title': section_title, 'text': text,\n",
    "                        'embedding': section_embedding})\n",
    "            if section[\"section_id\"] != \"2\":\n",
    "                doc = Document(page_content=text)\n",
    "                graph_extracted = llm_transformer.convert_to_graph_documents([doc])\n",
    "                if graph_extracted:\n",
    "                    graph_docs = graph_extracted[0]\n",
    "                    for node in graph_docs.nodes:\n",
    "                        node.id = clean_id(node.id)\n",
    "                    graph.add_graph_documents([graph_docs])\n",
    "                    for node in graph_docs.nodes:\n",
    "                        graph.query(\n",
    "                            '''MATCH (s:Section {id :$id})\n",
    "                            MATCH (n) WHERE n.id=$node_id\n",
    "                            MERGE (s)-[:CONTAINS]->(n)''', params={'node_id': node.id, 'id': section_id}\n",
    "                        )\n",
    "            else:\n",
    "\n",
    "                for unit in section[\"atomic_units\"]:\n",
    "                    print(unit)\n",
    "\n",
    "                    term = clean_id(unit[\"term\"])\n",
    "                    definition = unit[\"text\"]\n",
    "                    term_embedding = embeddings.embed_query(definition)\n",
    "                    graph.query(\n",
    "                        '''Match (s:Section {id :$sid}) MERGE (lc:LegalConcept {id:$term}) SET lc.definition=$definition, lc.source=\"Section 2\",lc.embedding=$embedding MERGE (s)-[:DEFINES]->(lc)''',\n",
    "                        params={'term': term, 'definition': definition, 'sid': section_id, 'embedding': term_embedding})\n",
    "                    try:\n",
    "                        doc = Document(page_content=definition)\n",
    "                        graph_extracted = llm_transformer.convert_to_graph_documents([doc])\n",
    "                        if graph_extracted:\n",
    "                            graph_docs = graph_extracted[0]\n",
    "                            for node in graph_docs.nodes:\n",
    "                                node.id = clean_id(node.id)\n",
    "                            graph.add_graph_documents([graph_docs])\n",
    "                            for node in graph_docs.nodes:\n",
    "                                if node.id.lower() != term:\n",
    "                                    graph.query(\n",
    "                                        '''MATCH (lc:LegalConcept {id:$term}) MATCH (n) WHERE n.id = $node_id MERGE (lc)-[:MENTIONS]->(n)''',\n",
    "                                        params={'node_id': node.id, 'term': term}\n",
    "                                    )\n",
    "                    except Exception as e:\n",
    "                        print(term, e)"
   ],
   "id": "c93f4f4e59b11bc0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "ret_query='''\n",
    "CALL db.index.vector.queryNodes('section_embedding',5,$embedding)\n",
    "YIELD node as s, score\n",
    "WHERE score>0.7\n",
    "WITH collect(\n",
    "{ type: 'Section',\n",
    "    title: s.title,\n",
    "    text: s.text,\n",
    "    score: score,\n",
    "    id: s.id\n",
    "}\n",
    ") as section_results\n",
    "\n",
    "CALL db.index.vector.queryNodes('concept_embedding',5,$embedding)\n",
    "YIELD node as lc, score\n",
    "WHERE score>0.7\n",
    "MATCH (section2:Section)-[:DEFINES]->(lc)\n",
    "WITH section_results, collect(\n",
    "{ type: 'definition',\n",
    "\n",
    "    term: lc.id,\n",
    "    definition: lc.definition,\n",
    "\n",
    "    score: score,\n",
    "    source: section2.title}) as concept_results\n",
    "\n",
    "UNWIND section_results as sec_res\n",
    "MATCH (s:Section {id: sec_res.id})\n",
    "OPTIONAL MATCH (s)-[:MENTIONS]->(entity)\n",
    "WITH section_results, concept_results, sec_res, labels(entity) as tags, entity\n",
    "WITH section_results, concept_results, sec_res, tags, entity,\n",
    "CASE\n",
    "    WHEN 'Authority' IN tags THEN 'Authority'\n",
    "    WHEN 'Offense' IN tags THEN 'Offense'\n",
    "    WHEN 'Penalty' IN tags THEN 'Penalty'\n",
    "    WHEN 'Remedy' IN tags THEN 'Remedy'\n",
    "    WHEN 'Stakeholder' IN tags THEN 'Stakeholder'\n",
    "    ELSE head(tags) END AS label\n",
    "\n",
    "WITH section_results, concept_results, sec_res, collect(DISTINCT entity.id + ' (' +label+ ')') as entities\n",
    "\n",
    "WITH\n",
    "collect({ type: 'Section',\n",
    "    title: sec_res.title,\n",
    "    text: sec_res.text,\n",
    "    score: sec_res.score,\n",
    "    mentions: entities\n",
    "}) as updated_section, concept_results\n",
    "\n",
    "RETURN {\n",
    "sections: updated_section,\n",
    "definitions: concept_results} as context\n",
    "\n",
    "'''\n"
   ],
   "id": "48cb34113ac7e09a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "groq_llm=ChatGroq(model_name=\"llama3-70b-8192\",temperature=0)",
   "id": "3208329fc137f0fb",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "user_query=input()\n",
    "user_query_vector=embeddings.embed_query(user_query)\n",
    "try:\n",
    "    result=graph.query(ret_query,params={'embedding':user_query_vector})\n",
    "    if not result:\n",
    "        print(\"No result from the graph\")\n",
    "\n",
    "    else:\n",
    "        context =result[0]['context']\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "llm_query=''\n",
    "if context:\n",
    "    if context['definitions']:\n",
    "        llm_query += 'Relevant Legal Definitions:\\n'\n",
    "        for item in context['definitions']:\n",
    "            llm_query+=f'Term: {item[\"term\"]}\\n'\n",
    "            llm_query += f'Source: {item[\"source\"]}\\n'\n",
    "            llm_query += f'Definition: {item[\"definition\"]}\\n'\n",
    "\n",
    "            llm_query += f'Score: {item[\"score\"]}\\n\\n'\n",
    "    if context['sections']:\n",
    "        llm_query += 'Relevant Legal Sections:\\n'\n",
    "        for item in context['sections']:\n",
    "            llm_query += f'Title: {item[\"title\"]}\\n'\n",
    "            llm_query += f'Text: {item[\"text\"]}\\n'\n",
    "\n",
    "            if item['mentions']:\n",
    "                mentions=[m for m in item['mentions']]\n",
    "                llm_query += f'Mentions: {\", \".join(mentions)}\\n'\n",
    "print(llm_query)\n",
    "\n"
   ],
   "id": "9bfd88911f8e173f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "system_prompt = \"\"\"\n",
    "You are an expert Legal Assistant for Indian Consumer Law.\n",
    "Answer the user's question STRICTLY based on the provided context below.\n",
    "\n",
    "Rules:\n",
    "1. Use the \"Relevant Definitions\" to clarify terms.\n",
    "2. Use the \"Relevant Sections\" to support your legal arguments.\n",
    "3. Pay special attention to \"Connected Entities\" to understand who is responsible (e.g., Authorities vs Stakeholders).\n",
    "4. If the answer is not in the context, state \"I cannot find the answer in the provided legal documents.\"\n",
    "\n",
    "Context:\n",
    "{llm_query}\n",
    "\"\"\""
   ],
   "id": "d04c2d216910662e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "prompt=ChatPromptTemplate.from_messages([('system',system_prompt),('user',user_query)])"
   ],
   "id": "bc360959c1729295",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "chain = prompt|groq_llm|StrOutputParser()\n"
   ],
   "id": "ebc137573dceeeb6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "response=chain.invoke({'llm_query':llm_query,'user':user_query})",
   "id": "bec5ef6e2cd2688c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "user_query",
   "id": "c6cd7b0ea8c13831",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "response",
   "id": "2ae382828c9745c4",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
